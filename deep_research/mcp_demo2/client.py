import asyncio
import os
import json
from typing import Optional, List
from contextlib import AsyncExitStack
from datetime import datetime
import re
from openai import OpenAI
from dotenv import load_dotenv
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
load_dotenv()


class MCPClient:

    def __init__(self):
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("DASHSCOPE_API_KEY")
        self.base_url = os.getenv("BASE_URL")
        self.model = os.getenv("MODEL")
        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® DASHSCOPE_API_KEY")
        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)
        self.session: Optional[ClientSession] = None

    async def connect_to_server(self, server_script_path: str):
        # å¯¹æœåŠ¡å™¨è„šæœ¬è¿›è¡Œåˆ¤æ–­ï¼Œåªå…è®¸æ˜¯ .py æˆ– .js
        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")

        # ç¡®å®šå¯åŠ¨å‘½ä»¤ï¼Œ.py ç”¨ pythonï¼Œ.js ç”¨ node
        command = "python" if is_python else "node"

        # æ„é€  MCP æ‰€éœ€çš„æœåŠ¡å™¨å‚æ•°ï¼ŒåŒ…å«å¯åŠ¨å‘½ä»¤ã€è„šæœ¬è·¯å¾„å‚æ•°ã€ç¯å¢ƒå˜é‡ï¼ˆä¸º None è¡¨ç¤ºé»˜è®¤ï¼‰
        server_params = StdioServerParameters(command=command, args=[server_script_path], env=None)

        # å¯åŠ¨ MCP å·¥å…·æœåŠ¡è¿›ç¨‹ï¼ˆå¹¶å»ºç«‹ stdio é€šä¿¡ï¼‰
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))

        # æ‹†åŒ…é€šä¿¡é€šé“ï¼Œè¯»å–æœåŠ¡ç«¯è¿”å›çš„æ•°æ®ï¼Œå¹¶å‘æœåŠ¡ç«¯å‘é€è¯·æ±‚
        self.stdio, self.write = stdio_transport

        # åˆ›å»º MCP å®¢æˆ·ç«¯ä¼šè¯å¯¹è±¡
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))

        # åˆå§‹åŒ–ä¼šè¯
        await self.session.initialize()

        # è·å–å·¥å…·åˆ—è¡¨å¹¶æ‰“å°
        response = await self.session.list_tools()
        tools = response.tools
        print("\nå·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in tools])

    async def process_query(self, query: str) -> str:
        # å‡†å¤‡åˆå§‹æ¶ˆæ¯å’Œè·å–å·¥å…·åˆ—è¡¨
        messages = [{"role": "user", "content": query}]
        response = await self.session.list_tools()

        available_tools = [
            {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "input_schema": tool.inputSchema
                }
            } for tool in response.tools
        ]

        # æå–é—®é¢˜çš„å…³é”®è¯ï¼Œå¯¹æ–‡ä»¶åè¿›è¡Œç”Ÿæˆã€‚
        # åœ¨æ¥æ”¶åˆ°ç”¨æˆ·æé—®åå°±åº”è¯¥ç”Ÿæˆå‡ºæœ€åè¾“å‡ºçš„ md æ–‡æ¡£çš„æ–‡ä»¶åï¼Œ
        # å› ä¸ºå¯¼å‡ºæ—¶è‹¥å†ç”Ÿæˆæ–‡ä»¶åä¼šå¯¼è‡´éƒ¨åˆ†ç»„ä»¶æ— æ³•è¯†åˆ«è¯¥åç§°ã€‚
        keyword_match = re.search(r'(å…³äº|åˆ†æ|æŸ¥è¯¢|æœç´¢|æŸ¥çœ‹)([^çš„\sï¼Œã€‚ã€ï¼Ÿ\n]+)', query)
        keyword = keyword_match.group(2) if keyword_match else "åˆ†æå¯¹è±¡"
        safe_keyword = re.sub(r'[\\/:*?"<>|]', '', keyword)[:20]
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        md_filename = f"sentiment_{safe_keyword}_{timestamp}.md"
        md_path = os.path.join("./sentiment_reports", md_filename)

        # æ›´æ–°æŸ¥è¯¢ï¼Œå°†æ–‡ä»¶åæ·»åŠ åˆ°åŸå§‹æŸ¥è¯¢ä¸­ï¼Œä½¿å¤§æ¨¡å‹åœ¨è°ƒç”¨å·¥å…·é“¾æ—¶å¯ä»¥è¯†åˆ«åˆ°è¯¥ä¿¡æ¯
        # ç„¶åè°ƒç”¨ plan_tool_usage è·å–å·¥å…·è°ƒç”¨è®¡åˆ’
        query = query.strip() + f" [md_filename={md_filename}] [md_path={md_path}]"
        messages = [{"role": "user", "content": query}]

        tool_plan = await self.plan_tool_usage(query, available_tools)

        tool_outputs = {}
        messages = [{"role": "user", "content": query}]

        # ä¾æ¬¡æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œå¹¶æ”¶é›†ç»“æœ
        for step in tool_plan:
            tool_name = step["name"]
            tool_args = step["arguments"]

            for key, val in tool_args.items():
                if isinstance(val, str) and val.startswith("{{") and val.endswith("}}"):
                    ref_key = val.strip("{} ")
                    resolved_val = tool_outputs.get(ref_key, val)
                    tool_args[key] = resolved_val

            # æ³¨å…¥ç»Ÿä¸€çš„æ–‡ä»¶åæˆ–è·¯å¾„ï¼ˆç”¨äºåˆ†æå’Œé‚®ä»¶ï¼‰
            if tool_name == "analyze_sentiment" and "filename" not in tool_args:
                tool_args["filename"] = md_filename
            if tool_name == "send_email_with_attachment" and "attachment_path" not in tool_args:
                tool_args["attachment_path"] = md_path

            result = await self.session.call_tool(tool_name, tool_args)

            tool_outputs[tool_name] = result.content[0].text
            messages.append({
                "role": "tool",
                "tool_call_id": tool_name,
                "content": result.content[0].text
            })

        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤ä¿¡æ¯ï¼Œå¹¶è¾“å‡ºä¿å­˜ç»“æœ
        final_response = self.client.chat.completions.create(
            model=self.model,
            messages=messages
        )
        final_output = final_response.choices[0].message.content

        # å¯¹è¾…åŠ©å‡½æ•°è¿›è¡Œå®šä¹‰ï¼Œç›®çš„æ˜¯æŠŠæ–‡æœ¬æ¸…ç†æˆåˆæ³•çš„æ–‡ä»¶å
        def clean_filename(text: str) -> str:
            text = text.strip()
            text = re.sub(r'[\\/:*?\"<>|]', '', text)
            return text[:50]

        # ä½¿ç”¨æ¸…ç†å‡½æ•°å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œç”Ÿæˆç”¨äºæ–‡ä»¶å‘½åçš„å‰ç¼€ï¼Œå¹¶æ·»åŠ æ—¶é—´æˆ³ã€è®¾ç½®è¾“å‡ºç›®å½•
        # æœ€åæ„å»ºå‡ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„ç”¨äºä¿å­˜è®°å½•
        safe_filename = clean_filename(query)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{safe_filename}_{timestamp}.txt"
        output_dir = "./llm_outputs"
        os.makedirs(output_dir, exist_ok=True)
        file_path = os.path.join(output_dir, filename)

        # å°†å¯¹è¯å†…å®¹å†™å…¥ md æ–‡æ¡£ï¼Œå…¶ä¸­åŒ…å«ç”¨æˆ·çš„åŸå§‹æé—®ä»¥åŠæ¨¡å‹çš„æœ€ç»ˆå›å¤ç»“æœ
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(f"ğŸ—£ ç”¨æˆ·æé—®ï¼š{query}\n\n")
            f.write(f"ğŸ¤– æ¨¡å‹å›å¤ï¼š\n{final_output}\n")

        print(f"ğŸ“„ å¯¹è¯è®°å½•å·²ä¿å­˜ä¸ºï¼š{file_path}")

        return final_output

    async def chat_loop(self):
        # åˆå§‹åŒ–æç¤ºä¿¡æ¯
        print("\nğŸ¤– MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")

        # è¿›å…¥ä¸»å¾ªç¯ä¸­ç­‰å¾…ç”¨æˆ·è¾“å…¥
        while True:
            try:
                query = input("\nä½ : ").strip()
                if query.lower() == 'quit':
                    break

                # å¤„ç†ç”¨æˆ·çš„æé—®ï¼Œå¹¶è¿”å›ç»“æœ
                response = await self.process_query(query)
                print(f"\nğŸ¤– AI: {response}")

            except Exception as e:
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def plan_tool_usage(self, query: str, tools: List[dict]) -> List[dict]:
        # æ„é€ ç³»ç»Ÿæç¤ºè¯ system_promptã€‚
        # å°†æ‰€æœ‰å¯ç”¨å·¥å…·ç»„ç»‡ä¸ºæ–‡æœ¬åˆ—è¡¨æ’å…¥æç¤ºä¸­ï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºå·¥å…·åï¼Œ
        # é™å®šè¿”å›æ ¼å¼æ˜¯ JSONï¼Œé˜²æ­¢å…¶è¾“å‡ºé”™è¯¯æ ¼å¼çš„æ•°æ®ã€‚
        print("\nğŸ“¤ æäº¤ç»™å¤§æ¨¡å‹çš„å·¥å…·å®šä¹‰:")
        print(json.dumps(tools, ensure_ascii=False, indent=2))
        tool_list_text = "\n".join([
            f"- {tool['function']['name']}: {tool['function']['description']}"
            for tool in tools
        ])
        system_prompt = {
            "role": "system",
            "content": (
                "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡è§„åˆ’åŠ©æ‰‹ï¼Œç”¨æˆ·ä¼šç»™å‡ºä¸€å¥è‡ªç„¶è¯­è¨€è¯·æ±‚ã€‚\n"
                "ä½ åªèƒ½ä»ä»¥ä¸‹å·¥å…·ä¸­é€‰æ‹©ï¼ˆä¸¥æ ¼ä½¿ç”¨å·¥å…·åç§°ï¼‰ï¼š\n"
                f"{tool_list_text}\n"
                "å¦‚æœå¤šä¸ªå·¥å…·éœ€è¦ä¸²è”ï¼Œåç»­æ­¥éª¤ä¸­å¯ä»¥ä½¿ç”¨ {{ä¸Šä¸€æ­¥å·¥å…·å}} å ä½ã€‚\n"
                "è¿”å›æ ¼å¼ï¼šJSON æ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« name å’Œ arguments å­—æ®µã€‚\n"
                "ä¸è¦è¿”å›è‡ªç„¶è¯­è¨€ï¼Œä¸è¦ä½¿ç”¨æœªåˆ—å‡ºçš„å·¥å…·åã€‚"
            )
        }

        # æ„é€ å¯¹è¯ä¸Šä¸‹æ–‡å¹¶è°ƒç”¨æ¨¡å‹ã€‚
        # å°†ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·çš„è‡ªç„¶è¯­è¨€ä¸€èµ·ä½œä¸ºæ¶ˆæ¯è¾“å…¥ï¼Œå¹¶é€‰ç”¨å½“å‰çš„æ¨¡å‹ã€‚
        planning_messages = [
            system_prompt,
            {"role": "user", "content": query}
        ]

        response = self.client.chat.completions.create(
            model=self.model,
            messages=planning_messages,
            tools=tools,
            tool_choice="none"
        )
        print(f"planning_messages:{planning_messages}")

        # æå–å‡ºæ¨¡å‹è¿”å›çš„ JSON å†…å®¹
        content = response.choices[0].message.content.strip()
        match = re.search(r"```(?:json)?\\s*([\s\S]+?)\\s*```", content)
        if match:
            json_text = match.group(1)
        else:
            json_text = content

        # åœ¨è§£æ JSON ä¹‹åè¿”å›è°ƒç”¨è®¡åˆ’
        try:
            plan = json.loads(json_text)
            print(f"å·¥å…·è°ƒç”¨åŸå§‹è¿”å›: {plan}")
            return plan if isinstance(plan, list) else []
        except Exception as e:
            print(f"âŒ å·¥å…·è°ƒç”¨é“¾è§„åˆ’å¤±è´¥: {e}\nåŸå§‹è¿”å›: {content}")
            return []

    async def cleanup(self):
        await self.exit_stack.aclose()


async def main():
    server_script_path = "/Users/zhangyf/PycharmProjects/train/llm_related/deep_research/mcp_demo2/server.py"
    client = MCPClient()
    try:
        await client.connect_to_server(server_script_path)
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())

